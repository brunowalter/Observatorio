{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import Request, urlopen\n",
    "import pandas as pd\n",
    "import io\n",
    "#import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "import plotly.express as px\n",
    "import chart_studio.plotly as py\n",
    "from datetime import datetime\n",
    "#pd.set_option(\"max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-invasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixar a base de dados caso_full.csv em  https://brasil.io/dataset/covid19/files/\n",
    "\n",
    "# Código retirado de https://gist.github.com/turicas/3e3621d61415e3453cd03a1997f7473f#file-brasil_io-py\n",
    "\n",
    "def get_database():\n",
    "\n",
    "    class BrasilIO:\n",
    "\n",
    "        base_url = \"https://api.brasil.io/v1/\"\n",
    "\n",
    "        def __init__(self, user_agent=None, auth_token=None):\n",
    "            \"\"\"\n",
    "            Caso queria fazer uma requisição na API, passe os parâmetros user_agent e auth_token.\n",
    "            Para fazer somente o download do arquivo completo, não é necessário passar nenhum parâmetro.\n",
    "            \"\"\"\n",
    "            self.__user_agent = user_agent\n",
    "            self.__auth_token = auth_token\n",
    "\n",
    "        def headers(self, api=True):\n",
    "            if api:\n",
    "                return {\n",
    "                    \"User-Agent\": f\"{self.__user_agent}\",\n",
    "                    \"Authorization\": f\"Token {self.__auth_token}\"\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    \"User-Agent\": \"python-urllib/brasilio-client-0.1.0\",\n",
    "                }\n",
    "\n",
    "\n",
    "        def api_request(self, path, query_string=None):\n",
    "            url = urljoin(self.base_url, path)\n",
    "\n",
    "            if query_string:\n",
    "                url += \"?\" + query_string\n",
    "\n",
    "            request = Request(url, headers=self.headers(api=True))\n",
    "\n",
    "            response = urlopen(request)\n",
    "            return json.load(response)\n",
    "\n",
    "        def data(self, dataset_slug, table_name, filters=None):\n",
    "            url = f\"dataset/{dataset_slug}/{table_name}/data/\"\n",
    "            filters = filters or {}\n",
    "            filters[\"page\"] = 1\n",
    "\n",
    "            finished = False\n",
    "            while not finished:\n",
    "                query_string = \"&\".join([f\"{k}={v}\" for k, v in filters.items()])\n",
    "                response = self.api_request(url, query_string)\n",
    "                next_page = response.get(\"next\", None)\n",
    "                for row in response[\"results\"]:\n",
    "                    yield row\n",
    "                filters = {}\n",
    "                url = next_page\n",
    "                finished = next_page is None\n",
    "\n",
    "        def download(self, dataset, table_name):\n",
    "            url = f\"https://data.brasil.io/dataset/{dataset}/{table_name}.csv.gz\"\n",
    "            request = Request(url, headers=self.headers(api=False))\n",
    "            response = urlopen(request)\n",
    "            return response\n",
    "\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        # Caso não tenha, cadastre-se no Brasil.io e gere seu Token\n",
    "        # Para mais instruções: https://blog.brasil.io/2020/10/10/como-acessar-os-dados-do-brasil-io/\n",
    "        user_agent = \"bwalter\"\n",
    "        auth_token = \"a569653206b56d7f8f0aa7ebee6871cafe1835dc\"\n",
    "\n",
    "        api = BrasilIO(user_agent, auth_token)\n",
    "\n",
    "        dataset_slug = \"covid19\"\n",
    "        table_name = \"caso_full\"\n",
    "\n",
    "\n",
    "         # Caso queira percorrer o CSV em memória:\n",
    "        response = api.download(dataset_slug, table_name)\n",
    "        fobj = io.TextIOWrapper(gzip.GzipFile(fileobj=response), encoding=\"utf-8\")\n",
    "\n",
    "        df = pd.read_csv(fobj)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-syndicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar base de dados atualizadas\n",
    "df = get_database()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar apenas cidade de Colombo\n",
    "df = df.loc[df[\"city\"] == \"Colombo\"]\n",
    "df = df[['date','order_for_place','new_confirmed','estimated_population']]\n",
    "df = df.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "# O número total de novos casos por 100.000 pessoas nos últimos 7 dias é calculado \n",
    "# adicionando o número de novos casos nos últimos 7 dias dividido pela população e\n",
    "# multiplicando por 100.000.\n",
    "populacao = df['estimated_population']\n",
    "# Acumulativo dos últimos 7 dias\n",
    "rolling = df.rolling(window=7).sum()\n",
    "rolling['MEDIA_MOVEL_7_DIAS'] = (rolling['new_confirmed']/populacao)*100000\n",
    "rolling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-delight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deixando apenas os ultimos 365 dias e apenas colunas de interesse\n",
    "rolling = rolling.reset_index()\n",
    "rolling = rolling[['date','MEDIA_MOVEL_7_DIAS']]\n",
    "rolling= rolling.tail(365).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-weapon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar CSV\n",
    "today = datetime.today()\n",
    "d = today.strftime(\"%Y%m%d\")\n",
    "data_atual = str(d)\n",
    "rolling.to_csv(f'./dados/csv/fator1-preprocessado-{data_atual}', sep=';', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-square",
   "metadata": {},
   "outputs": [],
   "source": [
    "hoje = today.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "fig = px.line(rolling, x=\"date\", y=\"MEDIA_MOVEL_7_DIAS\", title=f'Número de novos casos confirmados por 100 mil/hab nos últimos 7 dias - Atualizado em {hoje}', log_y=True, labels=dict(MEDIA_MOVEL_7_DIAS=\"Casos (escala logarítmica)\",date=\"\" ))\n",
    "\n",
    "\n",
    "fig.add_hrect(y0=50, y1=1400, line_width=0, fillcolor=\"red\", opacity=0.2)\n",
    "fig.add_hrect(y0=10, y1=50, line_width=0, fillcolor=\"yellow\", opacity=0.2)\n",
    "fig.add_hrect(y0=0, y1=10, line_width=0, fillcolor=\"green\", opacity=0.2)\n",
    "\n",
    "\n",
    "fig.update_yaxes(range=[0,3.15], tickmode=\"linear\", fixedrange= True) # linear range\n",
    "fig.update_xaxes(fixedrange= True)\n",
    "\n",
    "fig.show()\n",
    "fig.write_html(\"indicador-1.html\")\n",
    "\n",
    "py.sign_in(usuario, senha)\n",
    "plot_url = py.plot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-input",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
